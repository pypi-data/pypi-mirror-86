{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JIT compilation and parallelization with Numba\n",
    "\n",
    "This is a topical tutorial. If you are new to iminuit, you should go through the basic tutorial first. \n",
    "\n",
    "The time that iminuit requires to return a result, if that time is perceptible, is usually dominated by the execution time of the cost function. To get good performance, it recommended to use array arthimetic and scipy and numpy functions in the body of the cost function. Python loops should be avoided, but if they are unavoidable, [numba](https://numba.pydata.org/) can help. Numba can also parallelize numerical calculations to make full use of multi-core CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib numpy numba scipy iminuit\n",
    "from iminuit import Minuit\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import math\n",
    "from scipy.stats import expon, norm\n",
    "from matplotlib import pyplot as plt\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some toy data\n",
    "\n",
    "The standard fit in particle physics is the fit of a peak over some smooth background. We generate a Gaussian peak over exponential background, using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)  # fix seed\n",
    "\n",
    "# true parameters for signal and background\n",
    "truth = Namespace(n_sig=1000, f_bkg=10, sig=(5.0, 0.5), bkg=(0.0, 4.0))\n",
    "n_bkg = truth.n_sig * truth.f_bkg\n",
    "\n",
    "# make a data set\n",
    "x = np.empty(truth.n_sig + n_bkg)\n",
    "\n",
    "# fill m variables\n",
    "x[:truth.n_sig] = norm(*truth.sig).rvs(truth.n_sig)\n",
    "x[truth.n_sig:] = expon(*truth.bkg).rvs(n_bkg)\n",
    "\n",
    "# cut a range in x\n",
    "xrange = np.array((1.0, 9.0))\n",
    "ma = (xrange[0] < x) & (x < xrange[1])\n",
    "x = x[ma]\n",
    "\n",
    "plt.hist((x[truth.n_sig:], x[:truth.n_sig]), bins=50, stacked=True, label=(\"background\", \"signal\"))\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal starting values for iminuit\n",
    "start = np.array((truth.n_sig, n_bkg, truth.sig[0], truth.sig[1], truth.bkg[1]))\n",
    "\n",
    "\n",
    "# iminuit instance factory, will be called a lot in the benchmarks blow\n",
    "def m_init(fcn):\n",
    "    return Minuit.from_array_func(fcn,\n",
    "                                  start,\n",
    "                                  limit=((0, None), (0, None), None, (0, None),\n",
    "                                         (0, None)),\n",
    "                                  name=(\"ns\", \"nb\", \"mu\", \"sigma\", \"lambd\"),\n",
    "                                  errordef=Minuit.LIKELIHOOD,\n",
    "                                  pedantic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46424.886640130324"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extended likelihood (https://doi.org/10.1016/0168-9002(90)91334-8)\n",
    "# this version uses numpy and scipy and array arithmetic\n",
    "def nll(par):\n",
    "    n_sig, n_bkg, mu, sigma, lambd = par\n",
    "    s = norm(mu, sigma)\n",
    "    b = expon(0, lambd)\n",
    "    # normalisation factors are needed for pdfs, since x range is restricted\n",
    "    sn = s.cdf(xrange)\n",
    "    bn = b.cdf(xrange)\n",
    "    sn = sn[1] - sn[0]\n",
    "    bn = bn[1] - bn[0]\n",
    "    return (n_sig + n_bkg) - np.sum(np.log(s.pdf(x) / sn * n_sig + b.pdf(x) / bn * n_bkg))\n",
    "\n",
    "\n",
    "nll(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 ms ± 21.5 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 1\n",
    "m = m_init(nll) # setup time is negligible\n",
    "m.migrad();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 2 seconds on this computer. Let's see whether we can beat that. The code above is already pretty fast, because numpy and scipy routines are fast, and we spend most of the time in those. But these implementations do not parallelize the execution and are not optimised for this particular CPU, unlike numba-jitted functions.\n",
    "\n",
    "To use numba, in theory we just need to put the `njit` decorator on top of the function, but often that doesn't work out of the box. numba understands many numpy functions, but no scipy. We must evaluate the code that uses scipy in 'object mode', which is numba-speak for calling into the Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46424.886640130346"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first attempt to use numba\n",
    "@nb.njit(parallel=True)\n",
    "def jitted_nll_simple(par):\n",
    "    n_sig, n_bkg, mu, sigma, lambd = par\n",
    "    with nb.objmode(spdf=\"float64[:]\", bpdf=\"float64[:]\", sn=\"float64\", bn=\"float64\"):\n",
    "        s = norm(mu, sigma)\n",
    "        b = expon(0, lambd)\n",
    "        # normalisation factors are needed for pdfs, since x range is restricted\n",
    "        sn = np.diff(s.cdf(xrange))[0]\n",
    "        bn = np.diff(b.cdf(xrange))[0]\n",
    "        spdf = s.pdf(x)\n",
    "        bpdf = b.pdf(x)\n",
    "    no = n_sig + n_bkg\n",
    "    return no - np.sum(np.log(spdf / sn * n_sig + bpdf / bn * n_bkg))\n",
    "\n",
    "jitted_nll_simple(start) # test and warm-up JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 ms ± 15.9 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 1\n",
    "m = m_init(jitted_nll_simple)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is even a bit slower, wtf? Let's break the original function down by parts to see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 ms ± 116 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "1.08 ms ± 79.4 µs per loop (mean ± std. dev. of 3 runs, 500 loops each)\n",
      "72.8 µs ± 4.02 µs per loop (mean ± std. dev. of 3 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# let's time the body of the function\n",
    "n_sig, n_bkg, mu, sigma, lambd = start\n",
    "s = norm(mu, sigma)\n",
    "b = expon(0, lambd)\n",
    "# normalisation factors are needed for pdfs, since x range is restricted\n",
    "sn = np.diff(s.cdf(xrange))[0]\n",
    "bn = np.diff(b.cdf(xrange))[0]\n",
    "spdf = s.pdf(x)\n",
    "bpdf = b.pdf(x)\n",
    "no = n_sig + n_bkg\n",
    "# no - np.sum(np.log(spdf / sn * n_sig + bpdf / bn * n_bkg))\n",
    "\n",
    "%timeit -r 3 -n 100 norm(*start[2:4]).pdf(x)\n",
    "%timeit -r 3 -n 500 expon(0, start[4]).pdf(x)\n",
    "%timeit -r 3 -n 1000 np.sum(np.log(spdf / sn * n_sig + bpdf / bn * n_bkg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time is spend in those parts that numba could not accelerate and the total time is dominated by the slowest part.\n",
    "\n",
    "This, unfortunately, means we have to do much more manual work to make the function faster, since we have to replace the scipy routines with Python code that numba can accelerate and run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46424.88664013032"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwd = {\"parallel\": True, \"fastmath\": True}\n",
    "\n",
    "@nb.njit(**kwd)\n",
    "def sum_log(fs, spdf, fb, bpdf):\n",
    "    return np.sum(np.log(fs * spdf + fb * bpdf))\n",
    "\n",
    "\n",
    "@nb.njit(**kwd)\n",
    "def norm_pdf(x, mu, sigma):\n",
    "    invs = 1.0 / sigma\n",
    "    z = (x - mu) * invs\n",
    "    invnorm = 1 / np.sqrt(2 * np.pi) * invs\n",
    "    return np.exp(-0.5 * z**2) * invnorm\n",
    "\n",
    "\n",
    "@nb.njit(**kwd)\n",
    "def nb_erf(x):\n",
    "    y = np.empty_like(x)\n",
    "    for i in nb.prange(len(x)):\n",
    "        y[i] = math.erf(x[i])\n",
    "    return y\n",
    "\n",
    "\n",
    "@nb.njit(**kwd)\n",
    "def norm_cdf(x, mu, sigma):\n",
    "    invs = 1.0 / (sigma * np.sqrt(2))\n",
    "    z = (x - mu) * invs\n",
    "    return 0.5 * (1 + nb_erf(z))\n",
    "\n",
    "\n",
    "@nb.njit(**kwd)\n",
    "def expon_pdf(x, lambd):\n",
    "    inv_lambd = 1.0 / lambd\n",
    "    return inv_lambd * np.exp(-inv_lambd * x)\n",
    "\n",
    "\n",
    "@nb.njit(**kwd)\n",
    "def expon_cdf(x, lambd):\n",
    "    inv_lambd = 1.0 / lambd\n",
    "    return 1.0 - np.exp(-inv_lambd * x)\n",
    "\n",
    "\n",
    "def jitted_nll(par):\n",
    "    n_sig, n_bkg, mu, sigma, lambd = par\n",
    "    # normalisation factors are needed for pdfs, since x range is restricted\n",
    "    sn = norm_cdf(xrange, mu, sigma)\n",
    "    bn = expon_cdf(xrange, lambd)\n",
    "    sn = sn[1] - sn[0]\n",
    "    bn = bn[1] - bn[0]\n",
    "    spdf = norm_pdf(x, mu, sigma)\n",
    "    bpdf = expon_pdf(x, lambd)\n",
    "    no = n_sig + n_bkg\n",
    "    return no - sum_log(n_sig / sn, spdf, n_bkg / bn, bpdf)\n",
    "\n",
    "\n",
    "jitted_nll(start)  # test and warm-up JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.4 ms ± 860 µs per loop (mean ± std. dev. of 3 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 20\n",
    "m = m_init(jitted_nll)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to get a **4-5x** speed improvement over the initial code, which is impressive, but it cost us a lot of developer time. By putting these functions into a library, however, we would only have to pay the developer cost once. We close with a breakdown of how numba accelerated the parts of `jitted_nll`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 µs ± 19.4 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "61.8 µs ± 1.54 µs per loop (mean ± std. dev. of 3 runs, 500 loops each)\n",
      "65.9 µs ± 5.08 µs per loop (mean ± std. dev. of 3 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 3 -n 100 norm_pdf(x, *start[2:4])\n",
    "%timeit -r 3 -n 500 expon_pdf(x, start[4])\n",
    "%timeit -r 3 -n 1000 sum_log(n_sig / sn, spdf, n_bkg / bn, bpdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the total speed improvement mostly came from the acceleration of the normal and exponential pdfs, which got a lot faster, while the final sum was not accelerated singificantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
