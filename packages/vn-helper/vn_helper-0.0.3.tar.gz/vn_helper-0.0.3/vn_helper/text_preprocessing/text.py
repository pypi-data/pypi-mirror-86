import re
import string
from flashtext import KeywordProcessor
import json
import regex
import re

replace_list = {
    'Ã²a': 'oÃ ', 'Ã³a': 'oÃ¡', 'á»a': 'oáº£', 'Ãµa': 'oÃ£', 'á»a': 'oáº¡', 'Ã²e': 'oÃ¨', 'Ã³e': 'oÃ©', 'á»e': 'oáº»',
    'Ãµe': 'oáº½', 'á»e': 'oáº¹', 'Ã¹y': 'uá»³', 'Ãºy': 'uÃ½', 'á»§y': 'uá»·', 'Å©y': 'uá»¹', 'á»¥y': 'uá»µ', 'uáº£': 'á»§a',
    'aÌ‰': 'áº£', 'Ã´Ì': 'á»‘', 'uÂ´': 'á»‘', 'Ã´Ìƒ': 'á»—', 'Ã´Ì€': 'á»“', 'Ã´Ì‰': 'á»•', 'Ã¢Ì': 'áº¥', 'Ã¢Ìƒ': 'áº«', 'Ã¢Ì‰': 'áº©',
    'Ã¢Ì€': 'áº§', 'oÌ‰': 'á»', 'ÃªÌ€': 'á»', 'ÃªÌƒ': 'á»…', 'ÄƒÌ': 'áº¯', 'uÌ‰': 'á»§', 'ÃªÌ': 'áº¿', 'Æ¡Ì‰': 'á»Ÿ', 'iÌ‰': 'á»‰',
    'eÌ‰': 'áº»', 'Ã k': u' Ã  ', 'aË‹': 'Ã ', 'iË‹': 'Ã¬', 'ÄƒÂ´': 'áº¯', 'Æ°Ì‰': 'á»­', 'eËœ': 'áº½', 'yËœ': 'á»¹', 'aÂ´': 'Ã¡'}

standardwords = {'ok': ['ok', 'Ã´ kÃªi', 'okie', 'o kÃª', 'okey', 'Ã´kÃª', 'okay', 'oki', 'oke', 'okÃª'], 'Ä‘iá»‡n thoáº¡i thÃ´ng minh': ['smp'], 'cáº£m Æ¡n': ['cáº£m Æ¡n', 'cÃ¡m Æ¡n', 'tks', 'thks', 'thanks', 'ths', 'thank you', 'thank u'], 'giá»‘ng': ['giá»‘ng', 'simili', 'similar', 'giá»‘g'], 'khÃ´ng pháº£i': ['kp'], 'lÃ m sao': ['lsao'], 'thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­': ['tmÄ‘t'], 'android': ['andoid', 'androi'], 'Ä‘Ã©o': ['Ä‘Ã©o', 'dÃ©l', 'Ã©o'], 'dá»… thÆ°Æ¡ng': ['cute', 'dá»… thg', 'dthg'], 'vá»›i': ['vs', 'zá»›i'], 'váº­y': ['zá»µ', 'zá»‹', 'dáº¹', 'dá»µ', 'záº­y'], 'Ä‘Æ°á»£c': ['Ä‘Æ°Æ¡c', 'Ä‘c', 'Ä‘k', 'dk', 'Ä‘x', 'dc'], 'quÃ¡': ['wa', 'wÃ¡', 'qÃ¡'], 'Ä‘Æ°á»ng dáº«n': ['link'], 'bhxh': ['báº£o hiá»ƒm xÃ£ há»™i'], 'bhyt': ['báº£o hiá»ƒm y táº¿'], 'bhtn': ['báº£o hiá»ƒm thÃ¢n thá»ƒ'], 'kÃ­ch cá»¡': ['sz', 'size'], 'chuáº©n chÃ­nh hÃ£ng': ['authentic', 'auth'], 'xÃ³a': ['delete', 'del'], 'thÃ­ch': ['thick', 'thk', 'thich', 'thch', 'thik', 'like', 'thish'], 'tá»‘t': ['good', 'god', 'gÃºt', 'gut', 'tot', 'tÃ´t', 'nice', 'gud', 'wel done'], 'ráº¥t tá»‘t': ['perfect'], 'cá»­a hÃ ng': ['store', 'shop', 'sop'], 'sáº£n pháº©m': ['sp', 'product'], 'chiáº¿t kháº¥u': ['comision'], 'bÃ¬nh thÆ°á»ng': ['bt', 'bthg', 'btg', 'bÃ¬nh thg', 'bÃ¬nh tg'], 'thá»i gian': ['time', 'tgian', 'thgian'], 'giao hÃ ng': ['ship', 'sÃ­p', 'delivery'], 'xáº¥u': ['sáº¥u', 'xau'], 'mÃ¬nh': ['mik', 'mh', 'mih', 'mÃ¬h'], 'tÃ´i cÅ©ng váº­y': ['me too'], 'cháº¥t lÆ°á»£ng': ['quality', 'chat lÆ°á»£ng', 'cháº¥t lg'], 'hoÃ n háº£o': ['excelent'], 'lá»¡': ['nhá»¡'], 'dÃ¹ng': ['dÃ¹g'], 'apple': ['aple'], 'apple tv': ['apletv'], 'deathadder': ['deathader'], 'blackberry': ['blackbery'], 'tá»‡': ['bad', 'sad', 'por', 'poor'], 'háº¡n sá»­ dá»¥ng': ['date', 'exp', 'expiry date', 'hsd'], 'Ä‘áº¹p': ['Ä‘ep', 'dep'], 'tráº£ lá»i': ['trÃ£'], 'rá»“i': ['rá»“i', 'roÃ i', 'rÃ¹i'], 'twitter': ['twiter'], 'sá»­ dá»¥ng': ['sd', 'sá»­ dg', 'sá»­ dá»¥g', 'sdá»¥g'], 'Ä‘iá»‡n thoáº¡i': ['Ä‘t', 'Ä‘th', 'Ä‘thoai'], 'winner': ['winer'], 'nháº¯n tin': ['nt', 'inbox', 'inbx', 'ib', 'ntin'], 'xÃ i': ['sÃ i'], 'cÃ³': ['coÃ¡'], 'bÃ¢y giá»': ['bi h', 'bi giá»', 'bÃ¢y h', 'bi já»', 'bj', 'bjo'], 'facebook': ['fb', 'fbook', 'facebok'], 'ngon': ['delicious'], 'hÃ ng': ['hÃ g'], 'ios': ['iÃ³'], 'bluetooth': ['bluetooh', 'blutooth '], 'giáº£ máº¡o': ['fake'], 'matebook': ['matebok'], 'yÃªu': ['love', 'iu', 'iÃªu'], 'chÃº trá»ng': ['grace', 'chÃº trá»ng', 'chÃº chá»ng', 'trÃº trá»ng', 'trÃº chá»ng'], 'anh em': ['ae'], 'miá»…n phÃ­': ['free', 'fre'], 'Ä‘Ã¡ng yÃªu': ['lovely', 'Ä‘Ã¡ng iu', 'Ä‘Ã¡ng iÃªu'], 'vui váº»': ['zui záº»'], 'tuyá»‡t vá»i': ['toáº¹t vá»i', 'tuyá»‡t zá»i', 'toáº¹t zá»i', 'great'], 'ghÃ©t': ['gÃ©t'], 'dá»…': ['dá»ƒ'], 'viettel': ['vietel'], 'food': ['fod'], 'báº¡n': ['páº¡n'], 'nissan': ['nisan'], 'google': ['gogle', 'gg'], 'cÃ¡i': ['kÃ¡i'], 'hÃ¬nh': ['hÃ¬h'], 'cÃ²n': ['kÃ²n'], 'hiá»ƒu': ['há»‰u'], 'vacuum': ['vacum'], 'nhu cáº§u': ['nhu káº§u'], 'cá»§a': ['ká»§a'], 'qua': ['wa'], 'sá»‘ Ä‘iá»‡n thoáº¡i': ['sÄ‘t'], 'ecommerce': ['ecomerce'], 'mang': ['mag'], 'má»i ngÆ°á»i': ['mn'], 'gÃ¬': ['ji'], 'nhiÃªu': ['nhiu'], 'bao nhiÃªu': ['bn'], 'blueotooth': ['blueototh'], 'nhá»‰': ['nhá»·'], 'há»i': ['há»§i'], 'náº¿u': ['nháº¿u'], 'áº¡': ['áº­', 'á»£'], 'Ä‘Äƒng kÃ½': ['Ä‘Äƒng kÃ­', 'dkÃ½', 'dkÃ­', 'Ä‘kÃ­', 'Ä‘kÃ½'], 'nhÆ°ng': ['nhg', 'nhÆ°g'], 'sinh viÃªn': ['svien'], 'nhÆ° tháº¿ nÃ o': ['ntn'], 'tÄƒng': ['tÄƒg'], 'thÃ¬': ['thá»³'], 'chá»‰': ['chÄ©'], 'khi': ['khj'], 'luÃ´n': ['lun'], 'Ä‘Ã­ch': ['Ä‘Ã­ck', 'Ä‘Ã­k', 'djk'], 'thi': ['thj'], 'nÃ³': ['nÃ³a'], 'nÃ y': ['ná»³'], 'hÃ´m': ['hum'], 'biáº¿t': ['bik', 'bÃ­t'], 'nhiá»u': ['nhÃ¬u'], 'quan trá»ng': ['qtrong'], 'macbook': ['macbok'], 'Ä‘áº¿ch': ['Ä‘áº¿k'], 'pháº£i': ['fáº£i'], 'sim': ['sjm'], 'con': ['kon'], 'giá»': ['gjá»'], 'trÆ°á»›c': ['trc'], 'nÆ°á»›c': ['nc'], 'cÅ©ng': ['kÅ©ng', 'cÅ©g', 'kÅ©g'], 'mÃ ': ['mÃ k'], 'thÃ´i': ['hoi', 'thoi'], 'vÃ­ dá»¥': ['vd'], 'ngu': ['stupic']}



class Text:
    def __init__(self, text):
        self.text = text
        self.to_string()
        self.lowercase()

    def to_string(self):
        self.text = str(self.text)

    def lowercase(self):
        self.text = self.text.lower()

    def load_stopwords(self):
        with open('/data/vietnamese-stopwords.txt', 'r') as f:
            self.stopwords = f.read().splitlines()
            
    def load_standardwords(self):
        with open('/data/standard_words.json') as f_in:
            self.standardwords = json.load(f_in)


    def normalize(self):
        self.punctuate()
        self.regex_normalize()
        return self.text

    def punctuate(self):
        for k, v in replace_list.items():
            self.text = self.text.replace(k, v)

    def regex_normalize(self):
        patterns = ['\[([^\]=]+)(?:=[^\]]+)?\].*?\[\/\\1\\n]', r'\b(?:(?:https?|ftp)://)?\w[\w-]*(?:\.[\w-]+)+\S*',
                    "[\(\[].*?[\)\]]"]
        for pattern in patterns:
            self.text = re.sub(pattern, '', self.text)
        # chuyen punctuation thÃ nh space
        translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))
        self.text = self.text.translate(translator)

        # remove ná»‘t nhá»¯ng kÃ½ tá»± thá»«a
        self.text = self.text.replace(u'"', u' ')
        self.text = self.text.replace(u'ï¸', u'')
        self.text = self.text.replace('ğŸ»', '')
        self.text = self.text.replace('\r', '')

        # Removing multiple spaces
        self.text = re.sub(r'\s+', ' ', self.text)
        keyword_processor = KeywordProcessor(case_sensitive = False)
        keyword_dict = {'khÃ´ng': ['hÃ´ng', 'hem', 'kÃ´', 'hok', 'ko', 'khong',
                                  'k0', 'khog', 'kg', 'khg', 'ko', 'khÃ´g'],
                        'khÃ´ng ': ['k ', 'kh '], 'blackberry': ['bb']}
        keyword_processor.add_keywords_from_dict(keyword_dict)
        self.text = keyword_processor.replace_keywords(self.text)
        #Chuan hoa english words
        keyword_processor.add_keywords_from_dict(standardwords)
        self.text = keyword_processor.replace_keywords(self.text)
        self.text = re.sub(r'\s+', ' ', self.text)
        self.text = self.text.strip()

