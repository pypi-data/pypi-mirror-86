## try to reproduce yake.
import yake
import tqdm
import glob
import os

dataset_list = glob.glob("../datasets/*")
os.system("rm -rvf ./results_for_datasets_yake")

def read_contents(flx):
    return open(flx).read()

for dataset in dataset_list:
    directory = "results_for_datasets/{}".format(dataset.split("/")[-1])
    if not os.path.exists(directory):
        os.makedirs(directory)
    fx = dataset+"/docsutf8/*"
    for kwf in tqdm.tqdm(glob.glob(fx)):
        text = read_contents(kwf)
        kw_extractor = yake.KeywordExtractor()
        keywords = kw_extractor.extract_keywords(text)[0:10]
        kwid = kwf.split("/")[-1].replace(".txt","")
        kwx = directory+"/{}".format(kwid+".key")
        btx = "\n".join(list(x[1] for x in keywords))
        with open(kwx,"w") as wx:
            wx.write(btx)


./trec_eval -q -c -M1000 output/www.qrel output/www_..out
