FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.87228593709406010426e-01) (1, -1.08578562531578298733e-01) (2, 5.50435634516599214816e-02) (3, 7.00342657231213805424e-02) (4, -1.17688176966784102673e-02) (5, -1.36500528056047926162e-01) (6, -1.44472492540574076053e-02) (7, 1.31593963869901919850e+00) (8, -3.64469398123362584019e-02) (9, -1.87140289463135489623e-01) (10, -2.52375897996379661148e-01) (0, -2.32175231852942376420e+00) (1, 6.60324093305191373027e-01) (2, 6.66788991891464566386e-01) (3, 7.54351441167911973551e-01) (4, 7.59435017012676683024e-01) (5, 8.40185604566103250157e-01) (6, 6.00749102660440015278e-01) (7, 3.26969124344500405854e+00) (8, 3.45215069961979814650e+00) (9, 2.99554419714758202176e+00) (10, -1.49024280428150801558e-01) (0, 2.17230713592337316697e+01) (1, 2.68574179893355080573e-01) (2, 3.32327151482920246650e-01) (3, 2.94147545283655720283e-01) (4, 3.12267863934855061103e-01) (5, -1.75423837639563373614e+00) (6, -3.44052182570898201774e+00) (7, -3.72207044592546942852e+00) (8, -1.73521626885371427207e+00) (9, -1.22605135176973734090e+00) (10, 3.77913229471060319042e+00) (0, -4.77091306004812754082e-01) (1, 6.26470047049265899020e-01) (2, 7.68493975512725024934e-01) (3, 6.33441156707745589571e-01) (4, 7.58671830408316760774e-01) (5, 9.34274822050100484105e-01) (6, 6.35834512800711459946e-01) (7, 1.44712794104882869206e+00) (8, 3.24545685865144628579e+00) (9, 5.20594643919479871386e+00) (10, -1.03045703179216108225e+00) (0, 2.04845523298029352777e-01) (1, -1.23542509768116245961e-01) (2, -8.56702009211755821649e-03) (3, 4.15618123673322237277e-02) (4, -1.03010661695110555813e-01) (5, -5.13233222233675512314e-02) (6, -2.11745360199489751629e-01) (7, 2.59536597655311274124e+00) (8, -2.25602466792272304819e-01) (9, -3.87433046995790841827e-01) (10, -5.55402778337577007761e-01) (0, 1.02249486641240161511e+00) (1, -8.82198254766966907803e-03) (2, -9.03619487136890636725e-02) (3, -6.61449987739613082249e-02) (4, 7.06155415326068375270e-02) (5, -1.04121967320766235787e-02) (6, 4.67039078295343523806e-01) (7, -1.55582697313844575682e+00) (8, 2.59760745796225045456e-01) (9, -2.52363223609491796676e-03) (10, 1.12622125589019139724e+00) (0, 1.05921413646292705835e+00) (1, 5.00539727134735167730e-03) (2, -5.81586953289982624971e-02) (3, -1.39784734733578459159e-02) (4, -2.80160304196354729978e-02) (5, 1.40431715527019690404e-01) (6, 3.08407967149511130778e-01) (7, -1.37767906084909341757e+00) (8, 1.73018398806333018047e-01) (9, -7.73568688469203763480e-02) (10, 1.16687604927188237625e+00) (0, -1.08141873805611507531e-01) (1, 3.59302838686292869141e-01) (2, 3.15602203253095736635e-01) (3, 3.46858849170988303712e-01) (4, 3.03927806559389168672e-01) (5, 8.44682934495881809767e+00) (6, 5.58549863530187873373e-01) (7, -4.35556000637996376668e+00) (8, 7.97158012792756931475e+00) (9, 5.30036607946690541127e+00) (10, 2.87741448191443760507e-01) (0, 1.10236838132230907661e+00) (1, -9.79234535545398937506e-02) (2, 4.50138266831347708119e-02) (3, -6.08898621350815530406e-02) (4, -4.52258136421730891352e-02) (5, 1.99616140106163270085e-01) (6, 7.88842790002537430638e-01) (7, -1.84055219439755402000e+00) (8, 3.48990856992067111086e-01) (9, 1.88156282000714429603e-02) (10, 2.48636947302782546076e-01) (0, 1.86016069831785396671e-01) (1, 1.96553583113230762036e-02) (2, -8.48386992844067239217e-02) (3, 9.61674403825180275363e-03) (4, -7.81957318218670649479e-02) (5, -1.54315690139108258050e-01) (6, 2.51511911913869734558e-01) (7, 1.06533037298091692868e+00) (8, -1.16802291556424284180e-01) (9, 5.65252663377234718101e-02) (10, -2.51868401699020139084e-01) (11, 1.07301286290737007967e+00) (12, -2.28802341680081428033e-01) (13, -2.21160624254714194281e-01) (14, -2.03359422318889399017e-01) (15, 4.38284529874117478876e-01) (16, -2.65142891742075337280e-01) (17, -4.26682581636927460433e-01) (18, 1.37715181865098013070e+00) (19, -1.23993158376644818652e-01) (20, 1.02683089478019162755e+00) (21, 3.62428639085890735849e-01) 
