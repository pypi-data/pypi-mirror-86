FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.43109311262871119474e-01) (1, -7.20878517338992275132e-02) (2, -3.05900698611498433888e-02) (3, -2.22290066451764162236e-01) (4, -5.45344775626421252035e-02) (5, -1.41420279393310921456e-01) (6, 1.46043181665793397883e+00) (7, 3.33901032189968083319e-01) (8, 1.89254708111827790740e-01) (9, 9.61025043388179511794e-01) (10, -2.08438877861588461871e-01) (0, -5.25265548058736209125e-02) (1, 5.67649064737218544963e-01) (2, 5.18923038768428712686e-01) (3, 4.92098024266618860878e-01) (4, 5.22302204894679933389e-01) (5, 3.38794687273468009270e-01) (6, -5.27936641484589408435e+00) (7, 1.16596902611590480525e+00) (8, 6.17030298346147032529e-02) (9, -4.00960510089542676582e+00) (10, 7.56331885407223669660e+00) (0, 3.47690847362766897177e-01) (1, -6.78215771944890577494e-02) (2, -8.33843946488271731132e-02) (3, -1.53832919898785197566e-01) (4, -1.99274040761745957484e-01) (5, 3.84835258625790127551e-02) (6, 1.42245795824185350398e+00) (7, 3.46644249765204248703e-01) (8, 3.51793899248998898077e-01) (9, 8.91655578969902329334e-01) (10, -2.53769848112394336148e-01) (0, 3.68668201157266062218e-01) (1, -6.86579864688519336813e-02) (2, -7.30978545017842429310e-02) (3, -1.54824584371626799983e-01) (4, -1.14815175182402556819e-01) (5, -2.16613390436836139585e-01) (6, -8.40259406164699740316e-01) (7, 5.29085500299062760909e-01) (8, -1.62143462071039912153e-02) (9, -7.74533714719877197652e-01) (10, 1.60704291725911538324e-02) (0, -1.07417475132111817082e+00) (1, -5.17743876022492943711e-01) (2, -5.44715585005675961838e-01) (3, -3.84693907392417433488e-01) (4, -4.34058980834876539934e-01) (5, -1.25931305816106298145e+00) (6, 1.21469991939701067452e+01) (7, -1.79131335454756985825e+01) (8, -2.54155121458311983318e-01) (9, 9.18692282280837346775e+00) (10, -2.30173888027045103755e+00) (0, 6.36831353668727673245e-01) (1, -1.93447451393232272565e-01) (2, -1.24702859024629547635e-01) (3, -1.74555245141611026227e-01) (4, -7.75784880920504932300e-02) (5, -3.50860517990212006367e-01) (6, 2.39032307921966044595e-02) (7, -2.57866386713090978144e-01) (8, 1.11896131490830767763e-02) (9, -3.55643232825881172587e-01) (10, 1.09039179080517167897e+00) (0, 3.36969411739241955783e-02) (1, -1.36998387555326894827e-01) (2, -1.22510814468522362397e-02) (3, -9.27723446290154990512e-02) (4, -1.03147613386358791288e-01) (5, -4.67254266000908191625e-01) (6, -9.87683657915591095566e-01) (7, 6.78217724086624396129e-01) (8, 1.02841302679647084162e-01) (9, -5.92118148315317682773e+00) (10, -1.84189342593393673431e-02) (0, -4.04137978959739629925e-01) (1, -1.29249907277282555240e-01) (2, -1.26002951703723747867e-01) (3, -3.47901649696196260675e-02) (4, -9.78136502129400703387e-02) (5, -7.39423634449291156123e-01) (6, -1.08937041431217296328e+00) (7, 5.63827400923559540757e-01) (8, -4.53106137457307545091e-02) (9, -6.22745347481661659650e-01) (10, -1.31924744758530720912e-01) (0, -1.39863032286521828951e+01) (1, -9.05196207837428712395e-02) (2, -4.03666707949008329859e-02) (3, -1.00529051132616009667e-01) (4, -7.04927879647578858879e-02) (5, -6.93818923884787774892e-02) (6, 5.77820553456262331338e+00) (7, 3.40582470150113181262e+00) (8, 3.39312623559434545228e+00) (9, 2.75426459128178180435e+00) (10, -5.62205038304665905002e+00) (0, 7.60394334731052445875e-01) (1, -2.65805186930880912866e-02) (2, -1.60253307432292491086e-01) (3, -1.54841198236106425412e-01) (4, 2.14885411556973021652e-02) (5, -1.45898163482618942188e-01) (6, -6.47838204245634208256e-01) (7, 3.55629073076383972474e-01) (8, -1.20791352023540715654e-01) (9, -3.66593584766341684666e-01) (10, 1.74875711258276944626e-01) (11, 5.19201182939908578717e-01) (12, -2.54000232346656643762e-03) (13, 5.11324884216814545823e-01) (14, -1.81845158364056708189e-01) (15, -4.19889177808952573923e-01) (16, -1.99380254126174133456e-01) (17, -2.25101322901584161018e-01) (18, -1.47333636647627386207e-01) (19, 8.66602578304308535095e-01) (20, 9.15563567715364963473e-03) (21, 5.60481576870603626084e-01) 
