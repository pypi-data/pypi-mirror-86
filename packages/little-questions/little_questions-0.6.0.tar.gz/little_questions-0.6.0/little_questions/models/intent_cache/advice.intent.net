FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.22300069634914265748e-01) (1, 7.94063358603809943403e-01) (2, 8.23826550542210434003e-01) (3, 6.81573725341652503218e-01) (4, 7.45411670802925696577e-01) (5, 5.77163511770274606505e+00) (6, 6.22169294611058898425e+00) (7, -8.68860528188965375307e+00) (8, 5.88953299735400559456e+00) (9, 1.40310522979636265184e+00) (0, 1.35680322585927798373e-01) (1, 1.97348550684842069525e-02) (2, -9.42830040328112711778e-02) (3, -1.01472121404847251402e-01) (4, 8.11522857077511539092e-02) (5, -1.47380399235701842198e-01) (6, -2.57374621163361828879e-02) (7, -2.58756606890370721707e-01) (8, -1.44000873248076421973e-01) (9, 4.41226060776288009357e-01) (0, 2.82591131955066798831e-01) (1, -3.85544664388389329845e-02) (2, -9.37415874725074510510e-02) (3, -7.24548465734214525158e-02) (4, 6.21507772082596082752e-02) (5, -3.20851159393995499780e-01) (6, 3.29404584257732224728e-01) (7, -9.59582392127621142119e-02) (8, 1.39366411400592971059e-01) (9, 4.21256701736027749927e-01) (0, 2.27779560246531481704e-01) (1, -9.93465722190829403360e-02) (2, -4.40211088048907267511e-02) (3, -2.80405447470637447793e-02) (4, -8.26849952923747189004e-02) (5, -2.64619406246070776323e-01) (6, 8.94420662730548848840e-02) (7, 1.62732555289509528418e-02) (8, 1.86923416751885139442e-02) (9, 4.40582484844886768105e-01) (0, -2.71605031209850689145e-01) (1, -4.72170879583526589829e-02) (2, -8.37180038433243262075e-02) (3, -8.05232768397499548696e-02) (4, -3.91713251810241747108e-02) (5, -7.75594506006908046558e-01) (6, -1.69217976616551646352e+00) (7, 8.27649299402576943407e+00) (8, -4.71823130101852505902e+00) (9, -2.56515525802418431489e-01) (0, -1.78764957120001954927e-01) (1, 9.78326943163859014119e-03) (2, 1.90845444465159094771e-02) (3, 5.87026920561777368346e-03) (4, 4.48727175260065641593e-02) (5, -7.37095190096368479971e-02) (6, -1.41366252874695869091e-01) (7, 1.17059221478703867625e+00) (8, -1.92785675935190026209e-01) (9, -2.97221004062122040601e-01) (0, -2.80568261381494099549e-01) (1, -7.14155733329962377764e-02) (2, 4.74134090116513830931e-03) (3, -1.14081797430025388973e-03) (4, 1.03198141114999118045e-02) (5, -2.42625604117260584847e-02) (6, 1.00738641627955462232e-02) (7, 1.08004002110404195847e+00) (8, 1.98019911205941992471e-02) (9, -3.74116118593250612800e-01) (0, -7.24094658532103085946e+00) (1, -2.37298070125811111364e-01) (2, -3.18169503145449339421e-01) (3, -2.63184486561052977116e-01) (4, -3.50277631216280638249e-01) (5, 3.48715893503044371826e+00) (6, 3.50685942918648602129e-03) (7, 1.73029380998517456902e+00) (8, 9.50511914273852454027e-02) (9, -2.54371133816906258573e+00) (0, -3.42845896867639055028e-01) (1, -5.84531093318927091190e-03) (2, -4.41625977237688864541e-03) (3, 3.18420503071977015197e-02) (4, -5.77965926595495546603e-02) (5, -7.24034140551433891275e-02) (6, -5.03525456541416074896e-02) (7, 1.06526871607941808762e+00) (8, -8.09282281433576326790e-03) (9, -3.81281080686277307201e-01) (0, -3.21994152602063710145e-01) (1, -6.02582342517840596763e-03) (2, -2.11178982962416383895e-02) (3, 3.64655827771378851510e-02) (4, -6.65347898711012575301e-02) (5, -1.25674983366762221815e-01) (6, -4.69338355001180755621e-03) (7, 1.12833073572558584274e+00) (8, 6.16937842564933627831e-02) (9, -3.77379871004051126171e-01) (10, 1.07327148589413834401e+00) (11, -8.67342664525274531506e-01) (12, -1.33233895636647170502e-01) (13, 1.41214002975820172858e-02) (14, 3.92165043204478036554e-01) (15, 8.77926782869867472492e-01) (16, 4.16191294764273245210e-01) (17, 3.64013142742921291806e-01) (18, 3.85644505529035119817e-01) (19, 4.27724807320464639471e-01) (20, 2.69128103916851824096e-01) 
