{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Train the network using `dss.train`. The function will:\n",
    "- load train/val/test data\n",
    "- initialize the network\n",
    "- save all parameters for reproducibility\n",
    "- train the network and save the best network to disk\n",
    "- run inference and evaluate the network using the test data.\n",
    "\n",
    "In the process, four files will be created, all starting with the date_time the process was started (`YYYYMMDD_HHMMSS` as in `20192310_091032`):\n",
    "- `*_params.yaml` - training parameters etc\n",
    "- `*_arch.yaml` - network architecture\n",
    "- `*_model.h5` -  model architecture and weights\n",
    "- `*_results.h5` - evaluation results\n",
    "\n",
    "Training can be invoked from within a script/notebook (see below) or from the command line (command line interface created by [defopt](https://defopt.readthedocs.io/en/stable/index.html)):\n",
    "```shell\n",
    "python -m dss.train --data-dir dat/dmel_single_raw.npy --save-dir res --model-name tcn --kernel-size 16 --nb-filters 16 --nb-hist 512 --nb-epoch 20 -i\n",
    "```\n",
    "\n",
    "The above example uses the dataset created by [1_prepare_data.ipynb](1_prepare_data.ipynb). Note that the training data set and the model parameters are chosen for demonstration purposes and do not yield state-of-the-art performance.\n",
    "However, training for 10 epochs should yield a reasonably good model and takes around 15 minutes on a GPU. Training will typically converge after ~80 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janc/miniconda/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/janc/miniconda/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "INFO:root:loading data\n",
      "INFO:root:Parameters:\n",
      "INFO:root:{'data_dir': 'dat/dmel_single_raw.npy', 'model_name': 'tcn', 'nb_filters': 16, 'kernel_size': 8, 'nb_conv': 3, 'nb_hist': 512, 'batch_norm': True, 'save_dir': 'res', 'verbose': 1, 'nb_stacks': 2, 'with_y_hist': True, 'nb_epoch': 10, 'fraction_data': None, 'seed': None, 'ignore_boundaries': True, 'x_suffix': '', 'y_suffix': '', 'nb_pre_conv': 0, 'reduce_lr': False, 'batch_level_subsampling': False, 'batch_size': 32, 'sample_weight_mode': 'temporal', 'data_padding': 24, 'return_sequences': True, 'stride': 464, 'y_offset': 0, 'output_stride': 1, 'class_names': ['noise', 'pulse'], 'class_types': ['segment', 'event'], 'eventtimes_units': 'seconds', 'filename_endsample_test': [7980002], 'filename_endsample_train': [7960002, 11980003, 16380004, 20500005, 24540006], 'filename_endsample_val': [8300002], 'filename_startsample_test': [3990001], 'filename_startsample_train': [3980001, 7980002, 12180003, 16340004, 20440005], 'filename_startsample_val': [4150001], 'filename_train': ['dat.raw/PS_20130702114557_ch13_recording.npy', 'dat.raw/PS_20130625155828_ch11_recording.npy', 'dat.raw/PS_20130702144748_ch15_recording.npy', 'dat.raw/PS_20130628165930_ch11_recording.npy', 'dat.raw/PS_20130625155828_ch7_recording.npy'], 'filename_val': ['dat.raw/PS_20130628144304_ch15_recording.npy'], 'samplerate_x_Hz': 10000, 'samplerate_y_Hz': 10000, 'filename_test': ['dat.raw/PS_20130625111709_ch10_recording.npy'], 'nb_freq': 1, 'nb_channels': 1, 'nb_classes': 2, 'first_sample_train': 0, 'last_sample_train': None, 'first_sample_val': 0, 'last_sample_val': None}\n",
      "INFO:root:preparing data\n",
      "INFO:root:Training data:\n",
      "INFO:root:AudioSequence with 137600 batches each with 32 items.\n",
      "   Total of 20440005 samples with\n",
      "   each x=(1,) and\n",
      "   each y=(2,)\n",
      "INFO:root:Validation data:\n",
      "INFO:root:AudioSequence with 279 batches each with 32 items.\n",
      "   Total of 4150001 samples with\n",
      "   each x=(1,) and\n",
      "   each y=(2,)\n",
      "INFO:root:building network\n",
      "INFO:root:None\n",
      "INFO:root:start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TCN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tcn_initial_conv (Conv1D)       (None, 512, 16)      32          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_1_tanh_s0 (Con (None, 512, 16)      2064        tcn_initial_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 16)      0           tcn_dilated_conv_1_tanh_s0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 512, 16)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_1_s0_0.00 (None, 512, 16)      0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 512, 16)      272         tcn_spatial_dropout1d_1_s0_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 16)      0           tcn_initial_conv[0][0]           \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_2_tanh_s0 (Con (None, 512, 16)      2064        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_2_tanh_s0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 512, 16)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_2_s0_0.00 (None, 512, 16)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_2_s0_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 16)      0           add[0][0]                        \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_4_tanh_s0 (Con (None, 512, 16)      2064        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_4_tanh_s0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 512, 16)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_4_s0_0.00 (None, 512, 16)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_4_s0_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512, 16)      0           add_1[0][0]                      \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_8_tanh_s0 (Con (None, 512, 16)      2064        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_8_tanh_s0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512, 16)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_8_s0_0.00 (None, 512, 16)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_8_s0_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 16)      0           add_2[0][0]                      \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_16_tanh_s0 (Co (None, 512, 16)      2064        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_16_tanh_s0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 512, 16)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_16_s0_0.0 (None, 512, 16)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_16_s0_0.000\n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 16)      0           add_3[0][0]                      \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_1_tanh_s1 (Con (None, 512, 16)      2064        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_1_tanh_s1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 512, 16)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_1_s1_0.00 (None, 512, 16)      0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_1_s1_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 16)      0           add_4[0][0]                      \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_2_tanh_s1 (Con (None, 512, 16)      2064        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_2_tanh_s1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 512, 16)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_2_s1_0.00 (None, 512, 16)      0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_2_s1_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 16)      0           add_5[0][0]                      \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_4_tanh_s1 (Con (None, 512, 16)      2064        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_4_tanh_s1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 512, 16)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_4_s1_0.00 (None, 512, 16)      0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_4_s1_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 16)      0           add_6[0][0]                      \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_8_tanh_s1 (Con (None, 512, 16)      2064        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_8_tanh_s1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 512, 16)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_8_s1_0.00 (None, 512, 16)      0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_8_s1_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 16)      0           add_7[0][0]                      \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_16_tanh_s1 (Co (None, 512, 16)      2064        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 512, 16)      0           tcn_dilated_conv_16_tanh_s1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 512, 16)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_16_s1_0.0 (None, 512, 16)      0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 512, 16)      272         tcn_spatial_dropout1d_16_s1_0.000\n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 512, 16)      0           add_8[0][0]                      \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_1_tanh_s2 (Con (None, 512, 16)      2064        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 512, 16)      0           tcn_dilated_conv_1_tanh_s2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 512, 16)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_1_s2_0.00 (None, 512, 16)      0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 512, 16)      272         tcn_spatial_dropout1d_1_s2_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 512, 16)      0           add_9[0][0]                      \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_2_tanh_s2 (Con (None, 512, 16)      2064        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 512, 16)      0           tcn_dilated_conv_2_tanh_s2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 512, 16)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_2_s2_0.00 (None, 512, 16)      0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 16)      272         tcn_spatial_dropout1d_2_s2_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 512, 16)      0           add_10[0][0]                     \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_4_tanh_s2 (Con (None, 512, 16)      2064        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 512, 16)      0           tcn_dilated_conv_4_tanh_s2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 512, 16)      0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_4_s2_0.00 (None, 512, 16)      0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 16)      272         tcn_spatial_dropout1d_4_s2_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 512, 16)      0           add_11[0][0]                     \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_8_tanh_s2 (Con (None, 512, 16)      2064        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 512, 16)      0           tcn_dilated_conv_8_tanh_s2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 512, 16)      0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_8_s2_0.00 (None, 512, 16)      0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 512, 16)      272         tcn_spatial_dropout1d_8_s2_0.0000\n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 512, 16)      0           add_12[0][0]                     \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tcn_dilated_conv_16_tanh_s2 (Co (None, 512, 16)      2064        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 512, 16)      0           tcn_dilated_conv_16_tanh_s2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 512, 16)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tcn_spatial_dropout1d_16_s2_0.0 (None, 512, 16)      0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 512, 16)      272         tcn_spatial_dropout1d_16_s2_0.000\n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 512, 16)      0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 512, 16)      0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512, 2)       34          activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 2)       0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 35,106\n",
      "Trainable params: 35,106\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1000 steps, validate for 279 steps\n",
      "Epoch 1/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 00001: val_loss improved from inf to 0.02662, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 230s 230ms/step - loss: 0.0381 - val_loss: 0.0266\n",
      "Epoch 2/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00002: val_loss improved from 0.02662 to 0.02406, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 215s 215ms/step - loss: 0.0252 - val_loss: 0.0241\n",
      "Epoch 3/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0225\n",
      "Epoch 00003: val_loss improved from 0.02406 to 0.02238, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 219s 219ms/step - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 4/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0218\n",
      "Epoch 00004: val_loss improved from 0.02238 to 0.02176, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 236s 236ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 5/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00005: val_loss did not improve from 0.02176\n",
      "1000/1000 [==============================] - 239s 239ms/step - loss: 0.0205 - val_loss: 0.0220\n",
      "Epoch 6/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0204\n",
      "Epoch 00006: val_loss improved from 0.02176 to 0.02009, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 225s 225ms/step - loss: 0.0204 - val_loss: 0.0201\n",
      "Epoch 7/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0193\n",
      "Epoch 00007: val_loss did not improve from 0.02009\n",
      "1000/1000 [==============================] - 212s 212ms/step - loss: 0.0193 - val_loss: 0.0213\n",
      "Epoch 8/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0193\n",
      "Epoch 00008: val_loss improved from 0.02009 to 0.01977, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 226s 226ms/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 9/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0187\n",
      "Epoch 00009: val_loss improved from 0.01977 to 0.01901, saving model to res/20200515_100547_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 0.0187 - val_loss: 0.0190\n",
      "Epoch 10/10\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0195\n",
      "Epoch 00010: val_loss did not improve from 0.01901\n",
      "1000/1000 [==============================] - 226s 226ms/step - loss: 0.0195 - val_loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:re-loading last best model\n",
      "INFO:root:predicting\n",
      "INFO:root:evaluating\n",
      "INFO:root:[[3856463   14160]\n",
      " [  15502   93139]]\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "       noise      0.996     0.996     0.996   3870623\n",
      "       pulse      0.868     0.857     0.863    108641\n",
      "\n",
      "    accuracy                          0.993   3979264\n",
      "   macro avg      0.932     0.927     0.929   3979264\n",
      "weighted avg      0.993     0.993     0.993   3979264\n",
      "\n",
      "INFO:root:saving to res/20200515_100547_results.h5.\n"
     ]
    }
   ],
   "source": [
    "import dss.train\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "dss.train.train(model_name='tcn',  # see `dss.models` for valid model_names\n",
    "                data_dir='dat/dmel_single_raw.npy', \n",
    "                save_dir='res',\n",
    "                nb_hist=512,\n",
    "                kernel_size=8,\n",
    "                nb_filters=16,\n",
    "                ignore_boundaries=True,\n",
    "                verbose=1,\n",
    "                nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
